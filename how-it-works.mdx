---
title: "How It Works"
description: "Understand the MCP Blacksmith generation pipeline — from OpenAPI specification to running server."
---

## The generation pipeline

MCP Blacksmith converts an OpenAPI specification into a fully functional MCP server through a multi-stage pipeline:

```
OpenAPI Specification → Parse & Validate → Generate Code → Package Server
```

### 1. Parse and validate

Your OpenAPI specification is parsed and validated for structural correctness. Blacksmith supports:

- **OpenAPI 2.0** (Swagger)
- **OpenAPI 3.0.x**
- **OpenAPI 3.1.x**
- **OpenAPI 3.2.x**
- **JSON and YAML** formats

Specifications are validated for schema correctness, reference integrity, and required fields before generation begins. Issues that would produce broken code block generation and are reported with specific locations and suggested fixes.

You can also run a [dedicated validation pass](/generation/validation) separately to inspect your specification in detail. This is optional and non-blocking — results are shown in the Viewer tab of the dashboard.

### 2. Extract and enrich operations

Operations and their request/response schemas are extracted from the specification. Each API operation (e.g., `GET /users`, `POST /orders`) is mapped to an MCP tool with its parameters, request body, response schemas, and authentication requirements.

Optionally, these operations can be filtered and enhanced using [AI-enhanced passes](/generation/ai-passes). Passes can remove server-generated fields that AI agents shouldn't control, improve parameter descriptions for LLM readability, classify operations by importance, and optimize schemas for token efficiency. This curation step is what separates a raw API wrapper from a production-quality MCP server — it ensures AI agents see only the parameters they should set, with descriptions they can understand.

### 3. Generate code

The generator produces a complete Python project:

| File | Purpose |
|------|---------|
| `server.py` | MCP server with tool definitions for every operation |
| `_models.py` | Pydantic models for request/response validation |
| `_validators.py` | Format validators (dates, emails, UUIDs, etc.) |
| `_auth.py` | Authentication handlers for each security scheme |
| `.env` | Environment variables for credentials and configuration |
| `requirements.txt` | Python dependencies |
| `Dockerfile` | Production Docker build |
| `.mcp.json` | MCP client configuration template |
| `README.md` | Setup and usage instructions |

Each API operation becomes an MCP **tool** — an async function that handles parameter validation, authentication injection, HTTP request execution, and response processing.

### 4. Package and download

The complete server is packaged as a ZIP file. Extract it, install dependencies, configure credentials, and run — no additional code generation or compilation needed.

## Optional: AI-enhanced passes

The base generation is free and produces a fully functional server. For production use, you can optionally run [AI-enhanced passes](/generation/ai-passes) that:

- **Curate parameters** — Remove server-generated fields (timestamps, IDs) that AI agents shouldn't set
- **Optimize schemas** — Make parameter descriptions LLM-friendly and token-efficient
- **Filter redundant operations** — Identify and flag duplicate or deprecated endpoints

These passes consume credits and are entirely optional.

## What the generated server does at runtime

When an MCP client (like Claude) calls a tool:

1. **Validate** — Parameters are validated against Pydantic models
2. **Authenticate** — Correct credentials are injected based on the operation's authentication requirements
3. **Execute** — HTTP request is sent to the target API with retry logic and circuit breaking
4. **Validate response** — Response is optionally validated against the API's response schema
5. **Return** — Structured data is returned to the MCP client

All of this happens transparently. The AI agent sees simple tools with typed parameters and gets clean responses.

## Deployment considerations

<Note>
  Generated servers are designed for **self-hosted, single-tenant** deployment. Each server instance serves one user or application with its own credentials.
</Note>

- **Do not commit `.env` to version control** — it contains sensitive API credentials
- The server is stateful (credentials, connection pools) and expects a dedicated runtime environment
- For multi-tenant deployment with shared infrastructure, visit <a href="https://mcparmory.com" style={{color: 'hsl(199, 100%, 57%)'}}>MCP Armory</a>
